{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f244f7d-a63a-45ad-b1b6-f8a77deca09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scarches.dataset.trvae.data_handling import remove_sparsity\n",
    "from tranvae.model import EMBEDCVAE, TRANVAE\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sc.settings.set_figure_params(dpi=200, frameon=False)\n",
    "sc.set_figure_params(dpi=200)\n",
    "torch.set_printoptions(precision=3, sci_mode=False, edgeitems=7)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b224c5f2-4f8f-4457-a101-97d8f05ee72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_strat = \"batch\"\n",
    "cells_per_ct = 2000\n",
    "\n",
    "# Model Params\n",
    "latent_dim = 10\n",
    "use_mmd = False\n",
    "\n",
    "# Training Params\n",
    "tranvae_epochs = 500\n",
    "pretraining_epochs = 100\n",
    "alpha_epoch_anneal = 1e6\n",
    "eta = 1\n",
    "tau = 0\n",
    "clustering_res = 2\n",
    "labeled_loss_metric = \"dist\"\n",
    "unlabeled_loss_metric = \"dist\"\n",
    "class_metric = \"dist\"\n",
    "\n",
    "early_stopping_kwargs = {\n",
    "    \"early_stopping_metric\": \"val_classifier_loss\",\n",
    "    \"mode\": \"min\",\n",
    "    \"threshold\": 0,\n",
    "    \"patience\": 20,\n",
    "    \"reduce_lr\": True,\n",
    "    \"lr_patience\": 13,\n",
    "    \"lr_factor\": 0.1,\n",
    "}\n",
    "\n",
    "cell_type_key = [\"cell_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1957de8e-20d7-48b0-83fa-d94633a373a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "adata = sc.read(\n",
    "    f'{DATA_DIR}/benchmark_pbmc_shrinked.h5ad'\n",
    ")\n",
    "condition_key = 'condition'\n",
    "reference = ['Oetjen', '10X', 'Sun']\n",
    "query = ['Freytag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c6e8f4e-3c69-4cf6-882c-f3886d5f866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = remove_sparsity(adata)\n",
    "\n",
    "indices = np.arange(len(adata))\n",
    "#stratified label/unlabeled split\n",
    "if unlabeled_strat == \"batch\":\n",
    "    labeled_ind = indices[adata.obs.study.isin(reference)].tolist()\n",
    "    labeled_adata = adata[adata.obs.study.isin(reference)].copy()\n",
    "    unlabeled_adata = adata[adata.obs.study.isin(query)].copy()\n",
    "if unlabeled_strat == \"ct\":\n",
    "    labeled_ind = []\n",
    "    cts = adata.obs[cell_type_key[0]].unique().tolist()\n",
    "    for celltype in cts:\n",
    "        ct_indices = indices[adata.obs[cell_type_key[0]].isin([celltype])]\n",
    "        ct_sel_ind = np.random.choice(ct_indices, size=cells_per_ct, replace=False)\n",
    "        labeled_ind += ct_sel_ind.tolist()\n",
    "        print(celltype, len(ct_indices), len(ct_sel_ind), len(labeled_ind))\n",
    "    unlabeled_ind = np.delete(indices, labeled_ind).tolist()\n",
    "    labeled_adata = adata[labeled_ind].copy()\n",
    "    unlabeled_adata = adata[unlabeled_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18597262-2160-4af4-82aa-9d0e4a52dd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 128 10\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 10\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  10 128 10\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 4000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed = EMBEDCVAE(\n",
    "    adata=adata,\n",
    "    condition_key=condition_key,\n",
    "    inject_condition = ['encoder', 'decoder'],\n",
    "    embedding_dim = 10,\n",
    "    cell_type_keys=cell_type_key,\n",
    "    hidden_layer_sizes=[128, 128],\n",
    "    latent_dim=latent_dim,\n",
    "    use_mmd=use_mmd,\n",
    "    labeled_indices=labeled_ind,\n",
    "    unknown_ct_names=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89bd3a2d-92dd-4ec3-952c-17190dae1d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 128 9\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 10\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  10 128 9\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 4000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tranvae = TRANVAE(\n",
    "    adata=adata,\n",
    "    condition_key=condition_key,\n",
    "    cell_type_keys=cell_type_key,\n",
    "    hidden_layer_sizes=[128, 128],\n",
    "    latent_dim=latent_dim,\n",
    "    use_mmd=use_mmd,\n",
    "    labeled_indices=labeled_ind,\n",
    "    unknown_ct_names=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e06e89c5-7bf4-45bb-a74a-836c4a740e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████----------------| 20.0%  - val_loss: 1328.6840585562 - val_trvae_loss: 1328.6840585562\n",
      "Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.\n",
      "Leiden Clustering succesful. Found 39 clusters.\n",
      " |███████-------------| 37.6%  - val_loss: 1333.2449153020 - val_trvae_loss: 1332.6018160306 - val_classifier_loss: 0.6430961856 - val_unlabeled_loss: 1.6528987609 - val_labeled_loss: 0.6414432892\n",
      "ADJUSTED LR\n",
      " |█████████-----------| 46.4%  - val_loss: 1329.4798630934 - val_trvae_loss: 1329.0014883188 - val_classifier_loss: 0.4783808532 - val_unlabeled_loss: 1.4617866644 - val_labeled_loss: 0.4769190664\n",
      "ADJUSTED LR\n",
      " |█████████-----------| 47.8%  - val_loss: 1325.5334331806 - val_trvae_loss: 1325.0342829778 - val_classifier_loss: 0.4991648667 - val_unlabeled_loss: 1.4250707718 - val_labeled_loss: 0.4977397999\n",
      "Stopping early: no improvement of more than 0 nats in 20 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 217\n"
     ]
    }
   ],
   "source": [
    "tranvae.train(\n",
    "    n_epochs=tranvae_epochs,\n",
    "    early_stopping_kwargs=early_stopping_kwargs,\n",
    "    pretraining_epochs=pretraining_epochs,\n",
    "    alpha_epoch_anneal=alpha_epoch_anneal,\n",
    "    eta=eta,\n",
    "    tau=tau,\n",
    "    clustering_res=clustering_res,\n",
    "    labeled_loss_metric=labeled_loss_metric,\n",
    "    unlabeled_loss_metric=unlabeled_loss_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d191888e-912d-41d5-a171-f3ed43abc91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████----------------| 20.0%  - val_loss: 1311.4796142578 - val_trvae_loss: 1311.4796142578\n",
      "Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.\n",
      "Leiden Clustering succesful. Found 38 clusters.\n",
      " |████████████████----| 82.0%  - val_loss: 1314.9159358098 - val_trvae_loss: 1314.3373084435 - val_classifier_loss: 0.5786209450 - val_unlabeled_loss: 0.6284089868 - val_labeled_loss: 0.5779925356\n",
      "ADJUSTED LR\n",
      " |████████████████████| 100.0%  - val_loss: 1312.0196486253 - val_trvae_loss: 1311.5202636719 - val_classifier_loss: 0.4993728285 - val_unlabeled_loss: 0.5916365270 - val_labeled_loss: 0.4987811916\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 98\n"
     ]
    }
   ],
   "source": [
    "embed.train(\n",
    "    n_epochs=100,\n",
    "    early_stopping_kwargs=early_stopping_kwargs,\n",
    "    pretraining_epochs=20,\n",
    "    alpha_epoch_anneal=alpha_epoch_anneal,\n",
    "    eta=eta,\n",
    "    tau=tau,\n",
    "    clustering_res=clustering_res,\n",
    "    labeled_loss_metric=labeled_loss_metric,\n",
    "    unlabeled_loss_metric=unlabeled_loss_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b37bb1bd-b696-45f7-a9ae-b8a7e29e5e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.11e-01, -6.08e-02, -1.31e-03,  1.05e-01, -2.35e-02, -1.62e-03,\n",
       "         1.04e-02, -5.92e-03,  2.50e-02,  2.67e-02],\n",
       "       [ 1.42e-01,  2.03e-03, -1.68e-04, -1.93e-02,  6.06e-03,  1.69e-03,\n",
       "        -1.89e-01,  1.90e-03, -3.68e-03, -6.43e-03],\n",
       "       [ 2.04e-01,  1.09e-01, -1.64e-03,  7.70e-02,  5.83e-02,  6.50e-03,\n",
       "         2.00e-02, -1.48e-03, -6.41e-02, -1.34e-02],\n",
       "       [-2.13e-02, -2.73e-02,  3.16e-01,  9.28e-02,  3.83e-02,  2.43e-03,\n",
       "        -8.39e-02,  8.09e-05, -4.30e-02,  6.10e-02],\n",
       "       [-2.81e-02, -2.68e-03,  1.85e-04,  2.14e-01,  3.29e-03,  2.65e-03,\n",
       "        -6.26e-02,  3.53e-03,  3.46e-03, -1.93e-01],\n",
       "       [-8.59e-02, -1.54e-02, -4.78e-02,  1.64e-01, -5.57e-02,  1.27e-01,\n",
       "        -1.06e-01,  2.43e-03, -1.56e-01,  1.12e-01],\n",
       "       [-7.69e-02, -7.21e-02, -7.75e-02,  1.61e-01,  1.84e-01, -2.11e-02,\n",
       "        -1.02e-01, -2.58e-03, -6.15e-02,  1.10e-01],\n",
       "       [-5.12e-03,  1.30e-01,  1.11e-02,  1.81e-01, -8.33e-04,  3.22e-02,\n",
       "        -6.48e-02,  1.05e-03,  1.64e-01,  1.08e-01],\n",
       "       [-3.02e-03,  1.08e-01,  1.29e-02,  1.82e-01, -7.58e-02, -1.81e-01,\n",
       "        -5.32e-02,  2.82e-03, -5.13e-03,  8.70e-02]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.model.embedding.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c95f717c-d783-454c-841e-fc2f7ed3f5c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.DoubleTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-0588b5f269e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data_latent = embed.get_latent(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0munlabeled_adata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0munlabeled_adata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcondition_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0madata_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAnnData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/groups/ml01/workspace/carlo.dedonno/LATAQ/tranvae/model/embed_cvae_model.py\u001b[0m in \u001b[0;36mget_latent\u001b[0;34m(self, x, c, mean)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0msubsampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubsampled_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0mlatents\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/groups/ml01/workspace/carlo.dedonno/LATAQ/tranvae/model/embedding_cvae.py\u001b[0m in \u001b[0;36mget_latent\u001b[0;34m(self, x, c, mean)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecon_loss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0membed_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lataq/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lataq/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/anaconda3/envs/lataq/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.DoubleTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "data_latent = embed.get_latent(\n",
    "    unlabeled_adata.X, \n",
    "    unlabeled_adata.obs[condition_key].values\n",
    ")\n",
    "adata_latent = sc.AnnData(data_latent)\n",
    "adata_latent.obs['batch'] = unlabeled_adata.obs[condition_key].tolist()\n",
    "results_dict = tranvae.classify(\n",
    "    unlabeled_adata.X, \n",
    "    unlabeled_adata.obs[condition_key], \n",
    "    metric=class_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b99f6e-1541-412c-8f84-f3bd32ec7e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dec = EMBEDCVAE(\n",
    "    adata=adata,\n",
    "    condition_key=condition_key,\n",
    "    inject_condition = ['decoder'],\n",
    "    embedding_dim = 10,\n",
    "    cell_type_keys=cell_type_key,\n",
    "    hidden_layer_sizes=[128, 128],\n",
    "    latent_dim=latent_dim,\n",
    "    use_mmd=use_mmd,\n",
    "    labeled_indices=labeled_ind,\n",
    "    unknown_ct_names=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602a3b6-142e-45f0-a419-b9eaa5318d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dec.train(\n",
    "    n_epochs=tranvae_epochs,\n",
    "    early_stopping_kwargs=early_stopping_kwargs,\n",
    "    pretraining_epochs=pretraining_epochs,\n",
    "    alpha_epoch_anneal=alpha_epoch_anneal,\n",
    "    eta=eta,\n",
    "    tau=tau,\n",
    "    clustering_res=clustering_res,\n",
    "    labeled_loss_metric=labeled_loss_metric,\n",
    "    unlabeled_loss_metric=unlabeled_loss_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce449e-88b0-4b02-bcc6-cd76f2d17883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
